{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZnvntAwdQsh10weNmyTnHzaUI0Jn5ZRj","timestamp":1673094216208},{"file_id":"1X84ePmZnks-ScMLgiLEwwxd0SBizgCiL","timestamp":1666795139446}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This performs well on individual apples but poorly on bunches. NOW OUTDATED"],"metadata":{"id":"gvmaHBNy3WQp"}},{"cell_type":"markdown","source":["# Import our modules"],"metadata":{"id":"hSRYcHFHhAIV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxKLx7K6g6Jh"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os\n","from scipy import ndimage # multidimensional image processing\n","from skimage.color import rgb2hsv # image processing algorithms\n","from skimage.feature import local_binary_pattern"]},{"cell_type":"markdown","source":["### Change run time to gpu\n","Tools -> Runtime -> GPU"],"metadata":{"id":"Ew3wi_9AhNrN"}},{"cell_type":"markdown","source":["# Mount to google drive"],"metadata":{"id":"rZ1AxudphpiU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"v99x1de7hMIM","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"error","timestamp":1673086732780,"user_tz":-60,"elapsed":12111,"user":{"displayName":"Samuel Frank","userId":"04479992011217171071"}},"outputId":"537e6aef-4fe3-4dd6-8835-830181465068"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Get images and process\n","1. read them in\n","2. convert to hsv\n","3. convert to greyscale\n","4. utilise histogram equalisation\n"],"metadata":{"id":"O0Je1fRthvRe"}},{"cell_type":"code","source":["test_images=[]\n","# make some fake label values as an example\n","test_labels = np.arange(10)\n","# convert this 1D array to 2D array\n","test_labels = np.expand_dims(test_labels, axis=1)\n","\n","data_path = '/content/drive/Shareddrives/Machine_Vision_Group_4/MinneApple_Datasets/Smaller_Dataset/images/'\n","             \n","\n","for i in range(10):\n","  img_name = data_path + list(os.listdir(data_path))[i]\n","  print(img_name)\n","  test_images.append(img_name)"],"metadata":{"id":"hsbv4T6ZHQhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### If the above is still not very clear... use HSV colourspace as an alternative to the RGB colourspace!\n","\n","# HSV Colourspace\n","(Hue-saturation value)"],"metadata":{"id":"mDLDB1tqqqE7"}},{"cell_type":"code","source":["# select your image\n","img = cv2.imread(test_images[0])\n","print(test_images[0])\n","\n","hsv_img = rgb2hsv(img)\n","colour = img.copy() # make a deep copy of the original image\n","\n","\n","\n","# plt.imshow(hsv_img[:,:,0], cmap=\"gray\") # select this channel which we are using to distinguish our apples\n","\n","\n","hsv_c = (255*hsv_img[:,:,0]).astype(np.uint8) # scale data from [0, 1] to [0, 255] and convert to uint8 type\n","\n","equ = cv2.equalizeHist(hsv_c) # histogram equalisation\n","\n","# look at using LBP - this can \n","LBPimage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)       \n","lbp = local_binary_pattern(LBPimage, 8, 1, 'uniform')\n","\n","# perform thresholding! - thresh 1 and 2 are automatically defined but must be written in\n","thresh1, thresh_hsv_MANUAL = cv2.threshold(equ, thresh=90, maxval=255, type=cv2.THRESH_BINARY_INV) # manually selected threshold, low values to 255\n","thresh2, thresh_hsv_OTSU = cv2.threshold(hsv_c, thresh=128, maxval=255, type=cv2.THRESH_OTSU) # OTSU THRESHOLDING manually selected threshold, low values to 255\n","thresh_hsv_ADAPTIVE = cv2.adaptiveThreshold(hsv_c,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,301,3) # adaptive thresholding.\n","\n","\n","# NEED TO EXPLORE LAYERS OF MULTIPLE THRESHOLDING FOR THE BUNCH\n","# ALSO WORTH TRYING PREPROCESSING FUNCTIONS IN OPENCV - USE HISTOGRAM EQUALISATION.\n","#thresh2, thresh_hsv_OTSU = cv2.threshold(thresh_hsv_OTSU, thresh=128, maxval=255, type=cv2.THRESH_OTSU) # OTSU THRESHOLDING manually selected threshold, low values to 255\n","\n","plt.figure(figsize=(5, 8))\n","plt.subplot(2,3,1)\n","plt.imshow(img[:,:,::-1]) # the indexing here corrects the colour order from cv2.imread to plt.plot\n","plt.title(\"Original image\")\n","plt.subplot(2,3,2)\n","plt.imshow(hsv_img)\n","plt.subplot(2,3,3)\n","plt.imshow(hsv_img[:,:,0], cmap=\"gray\")\n","plt.subplot(2,3,4)\n","plt.imshow(thresh_hsv_MANUAL,cmap=\"gray\")\n","plt.title(\"Manual\")\n","plt.subplot(2,3,5)\n","plt.imshow(thresh_hsv_OTSU,cmap=\"gray\")\n","plt.title(\"Otsu\")\n","plt.subplot(2,3,6)\n","plt.imshow(thresh_hsv_ADAPTIVE,cmap=\"gray\")\n","plt.title(\"Adaptive\")\n","\n","#plt.savefig(\"figure.png\")\n","plt.show()\n","\n"],"metadata":{"id":"3C_2pI4vrFpb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Otsu is best, next:\n","## Morphological operations for separating our apples\n","### closing and erosion -> try opening if you can"],"metadata":{"id":"9eA8b0IRjRHz"}},{"cell_type":"code","source":["# create a structuring element\n","\n","test=cv2.imread(\"/content/drive/Shareddrives/Machine_Vision_Group_4/Current Algorithms/dataset1_front_451 test.png\")\n","# test = thresh_hsv_ADAPTIVE# choose the image you want to process (OTSU)\n","\n","\n","kernel = np.ones((3,3),np.uint8) # this shows us we are using 8 adjacent as we have a centre pixel surrounded by 8.\n","print(kernel)\n","# closing - dilation followed by erosion\n","#closing = cv2.morphologyEx(Threshold_image, cv2.MORPH_CLOSE, kernel, iterations=4)\n","closing = cv2.morphologyEx(test, cv2.MORPH_CLOSE, kernel, iterations=1)\n","# erosion - for a pixel that is surrounded by black pixels, remove all the surrounding\n","kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(13,13))\n","erosion = cv2.erode(closing,kernel,iterations = 1)\n","\n","\n","# closing\n","kernel = np.ones((11,11),np.uint8)\n","closing2 = cv2.morphologyEx(erosion, cv2.MORPH_CLOSE, kernel, iterations=5)\n","\n","# erosion\n","kernel = np.ones((7,7),np.uint8)\n","erosion2 = cv2.erode(closing2,kernel,iterations = 6)\n","\n","\n","# FH perform one extra round of closing erosion\n","\n","# closing\n","kernel = np.ones((11,11),np.uint8)\n","closing3 = cv2.morphologyEx(erosion2, cv2.MORPH_CLOSE, kernel, iterations=5)\n","\n","# erosion\n","kernel = np.ones((7,7),np.uint8)\n","erosion3 = cv2.erode(closing3,kernel,iterations = 6)\n","\n","# remove boarder pixels\n","erosion2[:50, :] = 0\n","erosion2[:, :50] = 0\n","erosion2[-50:, :] = 0\n","erosion2[:, -50:] = 0\n","\n","plt.figure(figsize=(16, 12))\n","plt.subplot(2,3,1)\n","#plt.imshow(Threshold_image,cmap=\"gray\")\n","plt.imshow(test,cmap=\"gray\")\n","plt.title(\"original\")\n","plt.subplot(2,3,2)\n","plt.imshow(closing,cmap=\"gray\")\n","plt.title(\"closing\")\n","plt.subplot(2,3,3)\n","plt.imshow(erosion,cmap=\"gray\")\n","plt.title(\"erosion\")\n","plt.subplot(2,3,4)\n","plt.imshow(erosion2,cmap=\"gray\")\n","plt.title(\"2 rounds of closing and erosion\")\n","plt.subplot(2,3,5)\n","plt.imshow(erosion3,cmap=\"gray\")\n","plt.title(\"3 rounds of closing and erosion\")"],"metadata":{"id":"SiTctpmdjn3b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Above, select which round produced the best result, use it below to mark the apples.\n","\n","# Find the centroid of each apple"],"metadata":{"id":"exgxfgILlcpX"}},{"cell_type":"code","source":["# a = np.ones(erosion.shape)\n","# inverted = a - erosion.\n","\n","# display = colour.copy()\n","display = cv2.bitwise_not(erosion)\n","labels, nlabels = ndimage.label(display)  # Label features in an array. Any non-zero values in input are counted as features and zero values are considered the background.\n","print(\"There are \" + str(nlabels) + \" apples\")\n","\n","centroid = ndimage.center_of_mass(display, labels, np.arange(nlabels) +1 ) # calculate the center of mass of the values of an array at labels.\n","\n","# draw circles representing the centroids\n","for cen in centroid:\n","  display = cv2.circle(display, (cen[1].astype(int), cen[0].astype(int)), radius=25, color=(255, 255, 255), thickness=-1)\n","\n","plt.figure()\n","# plt.imshow(erosion,cmap=\"gray\")\n","plt.imshow(display[:,:,::-1])"],"metadata":{"id":"RF4x1G3_lkkE"},"execution_count":null,"outputs":[]}]}